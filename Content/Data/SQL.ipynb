{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython2"
  },
  "name": "",
  "signature": "sha256:003e1740386f1ac69c8359be4866b9c7280729c30573e46474a1b9d446bbfde0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# SQL"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Learning Objectives**: Learn how to connect to and query SQL databases and get the results back as Pandas DataFrames."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import seaborn as sns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[SQL](http://en.wikipedia.org/wiki/SQL), or *Structured Query Lanauge* is a programming language focused on read, writing and transforming table based data sets, called *Relational Databases*. There are a number of reasons you might want to work with data in a SQL database:\n",
      "\n",
      "* They offer high performance for a limited set of operations. They are much faster than Pandas for many types of operations, but are more limited.\n",
      "* They can handle data sets that don't fit into memory. Pandas DataFrames have to fit in the memory of your computer, which limits their size. Data bases are typically stored on disk and don't have that limitation. This opens the door for working with much larger data sets. Most \"big data\" tools offer some sort of SQL interfaces.\n",
      "* The data you want/need to work with may already be in a SQL database.\n",
      "\n",
      "\n",
      "There are numerous free and open source databases that offer SQL interfaces:\n",
      "\n",
      "* [SQLite](http://www.sqlite.org/)\n",
      "* [MySQL](http://www.mysql.com/)\n",
      "* [PostgreSQL](http://www.postgresql.org/)\n",
      "\n",
      "It is a good idea to start with SQLite as it has good performance characteristics, doesn't require any specialized setup and comes already installed with Python.\n",
      "\n",
      "There are a number of different Python packages for working with SQL databases:\n",
      "\n",
      "* [SqlAlchemy](http://www.sqlalchemy.org/): foundation layer that other tools rely on.\n",
      "* [pandas.io.sql](http://pandas.pydata.org/pandas-docs/stable/io.html#io-sql)\n",
      "* [db.py](https://github.com/yhat/db.py)\n",
      "* [Blaze](http://blaze.pydata.org/docs/latest/index.html)\n",
      "\n",
      "For the purpose of this notebook we will be using the [Chinook](http://chinookdatabase.codeplex.com/) demo <b>database</b>. You should start by downloading the `.zip` file and putting the `.sqlite` file in this directory."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls *.sqlite"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Connecting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first step in working with an existing SQL database is to connect to it. This involves figuring out the appropriate connection string and passing it to `sqlalchemy.create_engine`. Here is the logic for our SQLite database:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from sqlalchemy import create_engine "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "te = create_engine('sqlite:///titanic.db')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice, this will use the file `titanic.db` in the current directory, which doesn't yet exist. SqlAlchemy will create it when needed. Here is the SqlAlchemy documentation for [engines and connection strings](http://docs.sqlalchemy.org/en/rel_0_9/core/engines.html)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## `pandas.io.sql`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pandas has basic capabilties to reading, writing and querying SQL databases. These function are in the `pandas.io.sql` subpackage:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from pandas.io import sql"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "tdf = sns.load_dataset('titanic')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tdf.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can write a table to a SQL database using the `to_sql` method, which takes the name of the table and an engine object:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tdf.to_sql('people', te)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have a populated database table, we can use Pandas to query the data set. The first thing we might want to do is read the entire table back into Python as a `DataFrame`. To emphasize that this is a new object, let's delete the original `DataFrame` we had."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "del tdf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then use the `read_sql_table` function with the table name and engine object to get the entire table:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "new_tdf = sql.read_sql_table('people', te)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_tdf.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Warning: don't do this unless you know exactly how large the table is. Databases can contain tables that are many times larger than the available memory on your system."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The real power of SQL databases comes from being able to query them using the SQL language. This can be done in Pandas using the `read_sql_query` function. To use this function, we need to cover the basic syntax of the SQL language. Here is a [high-level overview](http://www.w3schools.com/sql/default.asp) of the SQL language."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### SELECT"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `SELECT` statement is the most important part of the SQL language and is used to reads rows from a database table or tables. Here is an example that reads all (`*`) rows from the `people` table:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sql.read_sql_query('SELECT * FROM people;', te).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can read particular rows by name as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sql.read_sql_query('SELECT survived, sex, age, fare FROM people;', te).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### LIMIT"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can use the `LIMIT` clause to limit the number of rows that are returned. This is much more efficient that reading all  rows and then using `.head()`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sql.read_sql_query(\"\"\"\n",
      "SELECT survived, sex, age, fare FROM people\n",
      "    LIMIT 10;\n",
      "\"\"\", te)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### WHERE"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can use the `WHERE` clause to pick a subset of rows that satisfy certain criteria or tests. Notice how the notation for these tests is sligthly different from Python and Pandas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sql.read_sql_query(\"\"\"\n",
      "SELECT survived, sex, age, fare\n",
      "    FROM people\n",
      "    WHERE age>20 AND survived=0 and sex=\"male\";\n",
      "\"\"\", te).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### ORDER BY"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can sort the resulting rows using the `ORDER BY` clause and the name of a column or columns"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sql.read_sql_query(\"\"\"\n",
      "SELECT survived, sex, age, fare\n",
      "    FROM people\n",
      "    WHERE age>20 AND survived=0 and sex=\"male\"\n",
      "    ORDER BY fare;\n",
      "\"\"\", te).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Add `DESC` to reverse the order of the sort to descending:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sql.read_sql_query(\"\"\"\n",
      "SELECT survived, sex, age, fare\n",
      "    FROM people\n",
      "    WHERE age>20 AND survived=0 and sex=\"male\"\n",
      "    ORDER BY fare, age DESC;\n",
      "\"\"\", te).head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### SQL functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "SQL offers a host of functions that can applied to columns of data:\n",
      "\n",
      "* `AVG()`\n",
      "* `COUNT()`\n",
      "* `MIN()`\n",
      "* `MAX()`\n",
      "* `SUM()`\n",
      "\n",
      "Here we compute the number of males and the average fare they paid:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sql.read_sql_query(\"\"\"\n",
      "SELECT COUNT(sex), AVG(fare)\n",
      "    FROM people\n",
      "    WHERE sex=\"male\";\n",
      "\"\"\", te)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### GROUP BY"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `GROUP BY` clause allows you to perform split-apply-combine to a table to perform a wide range of transformations and aggregations. This works almost identically to the `groupby` method in Pandas. Here we using `GROUP BY` to compute averarge fares by gender:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sql.read_sql_query(\"\"\"\n",
      "SELECT sex, AVG(fare)\n",
      "    FROM people\n",
      "    GROUP BY sex\n",
      "\"\"\", te)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is the same computation on a Pandas `DataFrame`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_tdf.groupby('sex')['fare'].mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Working with `db.py`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another nice Python package for working wth SQL databases is the new [db.py](https://github.com/yhat/db.py) package from [yhat](https://yhathq.com/). You will need to install it using `pip`:\n",
      "\n",
      "```bash\n",
      "pip intall db.py\n",
      "```\n",
      "\n",
      "`db.py` is optimized for working interactively with databases. While it is brand new (Oct 26, 2014) I highly recommend it.\n",
      "\n",
      "Let's connect to the Chinook database we have in this directory. Notic how the connection syntax is slightly different from SqlAlchemy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import db"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = db.DB(filename='Chinook_Sqlite.sqlite', dbtype='sqlite')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's say you don't have any idea what a database contains and want to explore it. `db.py` provides a number of attributes and functions for doing that. First, let's look at the different tables in the database:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c.tables"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To see the details about a particular table, you can simply access it as a subattribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c.tables.Album"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the `.head()` method, you can get back the head of the table as a Pandas `DataFrame`. Note, the Album object is **not** a `DataFrame`. It is performing an SQL query to of the database to read this data (`SELECT * FROM Album LIMIT 6`)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c.tables.Album.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or you can retrieve a random sample of rows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c.tables.Album.sample()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c.tables"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This database has a number of columns that end with `Id`. These columns are designed to be used in joins and keys. We can find all of these columns across all tables using the `find_column` function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c.find_column('*Id')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c.tables.Album.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c.tables.Artist.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice how both the `Artist` and `Album` table have an `ArtistId` column. Let's perform a join on those two tables:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c.query(\"\"\"\n",
      "SELECT Album.Title, Artist.Name FROM Album\n",
      "    INNER JOIN Artist\n",
      "    ON Artist.ArtistId=Album.ArtistId\n",
      "    ORDER BY Artist.Name;\n",
      "\"\"\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c.query(\"\"\"\n",
      "SELECT Album.Title, Artist.Name FROM Album\n",
      "    INNER JOIN Artist\n",
      "    ON Artist.ArtistId=Album.ArtistId\n",
      "    ORDER BY Artist.Name;\n",
      "\"\"\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similar to Pandas, SQL support 4 types of joins (`INNER`, `LEFT`, `RIGHT`, `FULL`)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}