{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Objectives:** Get a general conceptual understanding of statistical modelling and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelling**, or **statistical modelling** is a very general approach for using data in a variety of productive ways. In other circles these same ideas go under the name **machine learning** or more trendy phrases such as **machine intelligence**. Some of the slipery terminology comes from the fact that research in this field has been done across different academic disciplines such as statistics, computer science, mathematics and physics. Each field has developed its own emphases and terminologies.\n",
    "\n",
    "Some of the goals of modelling include:\n",
    "\n",
    "* Predict future events based on past data.\n",
    "* Provide intuitive understanding data.\n",
    "* Provide a mathematical model for data that lacks first principles theoretical models (as in Physics).\n",
    "* Quantify uncertainties.\n",
    "* Learn generalizable information from data.\n",
    "\n",
    "As pointed out by Goodfellow et al., Mitchell (1997) provided a nice general definition of this idea of \"learning from data\":\n",
    "\n",
    "> A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E\n",
    "\n",
    "In this course, we will focus on two different ways of thinking about models:\n",
    "\n",
    "1. Forward = Generative models\n",
    "2. Backwards = Inference with models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of a **generative model** is that we can use a model to generate data. Usually, our models will have parameters that we get to (and have to) choose. Here is a diagram that shows show this works:\n",
    "\n",
    "**Model** $+$ **Parameters** $\\rightarrow$ **Generated Data**\n",
    "\n",
    "Let use this process to model the time between soccer goals in a soccer game. The appropriate distribution for this would be the exponential distribution. Let's say that we know the average time between goals is 20 minutes. Using this parameter and the exponential distribution (our model), we can create a dataset of the time between specific goals (100 of them!) in soccer games:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   7.59132714,   35.24821044,   12.61956233,   22.25872475,\n",
       "          3.04413594,    3.82006087,    7.36050517,    0.58394932,\n",
       "          0.84485984,   12.97077221,    9.6370772 ,    5.45550377,\n",
       "         38.72335154,    2.42956676,  101.23131309,    7.2058877 ,\n",
       "          6.7629777 ,   28.2692836 ,    0.44706828,   23.54272256,\n",
       "         59.69332611,    1.73749971,    6.9130371 ,   48.8442661 ,\n",
       "         80.06098783,   21.26730016,   16.32330468,   77.55670084,\n",
       "          1.61846163,    1.82737721,    1.66911205,    1.42836504,\n",
       "         36.46354179,   37.5226886 ,   14.10774694,   16.82212717,\n",
       "          3.85438617,    3.23929661,   13.27884541,    0.21476899,\n",
       "          7.59656624,   75.21928853,   23.89276814,   52.80049842,\n",
       "         12.01671851,   83.02955897,   11.61764102,    1.92984441,\n",
       "         11.1990382 ,    8.04769749,    9.12252184,   43.63230212,\n",
       "         24.61005102,    5.8365254 ,   30.1476597 ,   19.15471962,\n",
       "         23.82252693,   15.64429281,    6.38606855,  110.8389773 ,\n",
       "          3.0665022 ,   35.43225356,   20.91872273,    9.12030536,\n",
       "         31.27435198,    3.13921788,    5.92995448,   10.97769975,\n",
       "          3.88294401,    3.32045943,   33.34796382,    3.78449745,\n",
       "         18.93570032,   16.26117864,   12.69124673,    9.1603996 ,\n",
       "          2.71608897,    9.36648508,    0.55927551,   27.79489843,\n",
       "         31.96039011,    0.16210062,    8.69557181,   19.02203984,\n",
       "         11.4682279 ,    0.55394352,   10.73936382,   38.26183564,\n",
       "          8.46739604,   78.27444471,    5.51985254,   14.37137818,\n",
       "          8.65682066,   18.62795113,   11.3421351 ,   17.41510105,\n",
       "          5.69520142,   68.7712585 ,   36.7352938 ,    3.26758434])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "β = 20 # Parameter\n",
    "data = np.random.exponential(β, 100) # Model\n",
    "data # data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then visualize this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAADNdJREFUeJzt3W+MZYVZx/HvT8BqoQaQgSB/HNqQWmJSaCYExRgs1lAwQhNNSkzlBcn2RYlgSMxaX1jfbZMW1KQh2RYEDeIfoEIKqZKVhDRRdBYJLC4VrGsLrOwQbEHftMDji3u2mSw7zJ177+zMffh+ksm998y5e5+zZ/LN2TP3nk1VIUmafz+y1QNIkmbDoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJauL4Y/lip512Wi0uLh7Ll5Skubd3795XqmphvfWOadAXFxdZXl4+li8pSXMvyX+Ns56nXCSpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJamJY/pJ0Wks7nxo4uce2HXVDCeRpO3JI3RJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWpi3aAnOSfJo0n2J3kmyY3D8s8leTHJk8PXlZs/riRpLeP8F3RvADdX1RNJ3gfsTfLI8L1bq+oLmzeeJGlc6wa9qg4CB4f7ryfZD5y12YNJkjZmQ+fQkywCFwGPD4tuSPJUkjuSnDLj2SRJGzB20JOcBNwH3FRVrwG3AR8ALmR0BP/FNZ63I8lykuWVlZUZjCxJOpqxgp7kBEYxv7uq7geoqper6s2qegv4MnDx0Z5bVburaqmqlhYWFmY1tyTpCOO8yyXA7cD+qrpl1fIzV632CWDf7MeTJI1rnHe5XAp8Cng6yZPDss8C1ya5ECjgAPDpTZlQkjSWcd7l8g0gR/nWw7MfR5I0KT8pKklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqYnjt3qAY2Fx50NTPf/ArqtmNIkkbR6P0CWpCYMuSU0YdElqYt2gJzknyaNJ9id5JsmNw/JTkzyS5Lnh9pTNH1eStJZxjtDfAG6uqg8BlwCfSXIBsBPYU1XnA3uGx5KkLbJu0KvqYFU9Mdx/HdgPnAVcDdw1rHYXcM1mDSlJWt+GzqEnWQQuAh4HzqiqgzCKPnD6rIeTJI1v7KAnOQm4D7ipql7bwPN2JFlOsryysjLJjJKkMYwV9CQnMIr53VV1/7D45SRnDt8/Ezh0tOdW1e6qWqqqpYWFhVnMLEk6inHe5RLgdmB/Vd2y6lsPAtcN968DHpj9eJKkcY3z0f9LgU8BTyd5clj2WWAX8NdJrge+DfzG5owoSRrHukGvqm8AWePbl892HEnSpPykqCQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJamLdoCe5I8mhJPtWLftckheTPDl8Xbm5Y0qS1jPOEfqdwBVHWX5rVV04fD0827EkSRu1btCr6jHg1WMwiyRpCtOcQ78hyVPDKZlTZjaRJGkikwb9NuADwIXAQeCLa62YZEeS5STLKysrE76cJGk9EwW9ql6uqjer6i3gy8DF77Du7qpaqqqlhYWFSeeUJK1joqAnOXPVw08A+9ZaV5J0bBy/3gpJ7gEuA05L8gLwB8BlSS4ECjgAfHoTZ5QkjWHdoFfVtUdZfPsmzCJJmoKfFJWkJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNbHuR/8Fizsfmvi5B3ZdNcNJJGltHqFLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1IT6wY9yR1JDiXZt2rZqUkeSfLccHvK5o4pSVrPOEfodwJXHLFsJ7Cnqs4H9gyPJUlbaN2gV9VjwKtHLL4auGu4fxdwzYznkiRt0KTn0M+oqoMAw+3psxtJkjSJTf+laJIdSZaTLK+srGz2y0nSu9akQX85yZkAw+2htVasqt1VtVRVSwsLCxO+nCRpPZMG/UHguuH+dcADsxlHkjSpcd62eA/wj8AHk7yQ5HpgF/CxJM8BHxseS5K20PHrrVBV167xrctnPIskaQp+UlSSmjDoktTEuqdcNJ3FnQ9N/NwDu66a4SSSuvMIXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNePlcvc00l/wFL/srbRWP0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTUz10f8kB4DXgTeBN6pqaRZDSZI2bhbXcvmlqnplBn+OJGkKnnKRpCamDXoBf59kb5IdsxhIkjSZaU+5XFpVLyU5HXgkybNV9djqFYbQ7wA499xzp3y5d5dpL2Mr6d1lqiP0qnppuD0EfBW4+Cjr7K6qpapaWlhYmOblJEnvYOKgJzkxyfsO3wd+Bdg3q8EkSRszzSmXM4CvJjn85/xFVX19JlNJkjZs4qBX1beAD89wFknSFHzboiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpiVn8j0WS5tA0l2c+sOuqGU6iWfEIXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTfi2RWmOTfPWQ/XjEbokNWHQJakJgy5JTRh0SWrCoEtSEwZdkprwbYuauXfjW+mmufrgu/Hva6ts5d/1sbhCpUfoktSEQZekJgy6JDUxVdCTXJHkm0meT7JzVkNJkjZu4qAnOQ74EvBx4ALg2iQXzGowSdLGTHOEfjHwfFV9q6q+D/wlcPVsxpIkbdQ0QT8L+M6qxy8MyyRJW2Ca96HnKMvqbSslO4Adw8P/TfLNCV/vNOCVCZ+73blt8+mH25bPb/Eks/eO+23Ot3dLfian/Dv76XFWmiboLwDnrHp8NvDSkStV1W5g9xSvA0CS5apamvbP2Y7ctvnkts2nzts2zSmXfwHOT3Jekh8FPgk8OJuxJEkbNfERelW9keQG4O+A44A7quqZmU0mSdqQqa7lUlUPAw/PaJb1TH3aZhtz2+aT2zaf2m5bqt72e0xJ0hzyo/+S1MS2D3qnywskOSfJo0n2J3kmyY3D8lOTPJLkueH2lK2edVJJjkvyr0m+Njw+L8njw7b91fAL9LmT5OQk9yZ5dth/P9dlvyX5neHncV+Se5L82LzutyR3JDmUZN+qZUfdTxn5k6EtTyX5yNZNPhvbOugNLy/wBnBzVX0IuAT4zLA9O4E9VXU+sGd4PK9uBPavevx54NZh2/4HuH5LppreHwNfr6qfAT7MaBvnfr8lOQv4bWCpqn6W0RscPsn87rc7gSuOWLbWfvo4cP7wtQO47RjNuGm2ddBpdnmBqjpYVU8M919nFIWzGG3TXcNqdwHXbM2E00lyNnAV8JXhcYCPAvcOq8zltiX5CeAXgdsBqur7VfVdmuw3Rm+O+PEkxwPvBQ4yp/utqh4DXj1i8Vr76Wrgz2rkn4CTk5x5bCbdHNs96G0vL5BkEbgIeBw4o6oOwij6wOlbN9lU/gj4XeCt4fFPAt+tqjeGx/O6/94PrAB/OpxO+kqSE2mw36rqReALwLcZhfx7wF567LfD1tpP7fqy3YM+1uUF5k2Sk4D7gJuq6rWtnmcWkvwqcKiq9q5efJRV53H/HQ98BLitqi4C/o85PL1yNMP55KuB84CfAk5kdCriSPO439bT5efzh7Z70Me6vMA8SXICo5jfXVX3D4tfPvxPveH20FbNN4VLgV9LcoDRqbGPMjpiP3n4pzzM7/57AXihqh4fHt/LKPAd9tsvA/9ZVStV9QPgfuDn6bHfDltrP7Xry3YPeqvLCwznlG8H9lfVLau+9SBw3XD/OuCBYz3btKrq96rq7KpaZLSf/qGqfhN4FPj1YbV53bb/Br6T5IPDosuBf6PBfmN0quWSJO8dfj4Pb9vc77dV1tpPDwK/Nbzb5RLge4dPzcytqtrWX8CVwL8D/wH8/lbPM+W2/AKjf9I9BTw5fF3J6FzzHuC54fbUrZ51yu28DPjacP/9wD8DzwN/A7xnq+ebcJsuBJaHffe3wCld9hvwh8CzwD7gz4H3zOt+A+5h9LuAHzA6Ar9+rf3E6JTLl4a2PM3onT5bvg3TfPlJUUlqYrufcpEkjcmgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU38PyMox8wScq9FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc08058208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example clarifies the choices that you have to make when building a generative model:\n",
    "\n",
    "* You have to pick a model to use\n",
    "* You have to pick the parameters of the model\n",
    "\n",
    "To assess if you have made good choice, you will have to perform some sort of comparison of the generated data, with actual observations from the system you are intenting to model. In general, you would like to know that the parameters of your model are choosen in a way that makes your model useful. That is exactly what **inference** provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Inference with models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference** is a way of **learning from data**. In the context of generative models, inference allow you to go backwards from **observed data** to parameters that optimize how well the model works for that observed data. Here is a diagram of inference:\n",
    "\n",
    "**Model** $+$ **Observed Data** + **Training** $\\rightarrow$ **Parameters**\n",
    "\n",
    "Notice the similarities to generative modelling:\n",
    "\n",
    "* You still have to pick your model!!!\n",
    "\n",
    "However the differences are most important:\n",
    "\n",
    "* The data is not generated, it is observed\n",
    "* The parameters are predicted, rather than guessed\n",
    "* A **training** step is required.\n",
    "\n",
    "The magic of inference is that once you have performed inference to find the best parameters, you can turn it around and generate predictions:\n",
    "\n",
    "**Model** $+$ **Best Parameters** $\\rightarrow$ **Predictions**\n",
    "\n",
    "If your model and parameters are good, you should be able to predict outcomes you haven't seen before.\n",
    "\n",
    "Let's see how this would work with the above soccer goal data. You have been handed a small dataset of the times (in minutes) between soccer goals. This is your observed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observed_data = np.array(\n",
    "    [  6.57946838,  16.66471659,  52.11420679,  25.64266511,\n",
    "       10.90558697,  17.74796824,   8.0075313 ,   3.98989899,\n",
    "       13.46723746,  24.90308858]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are again going to pick the exponential distribution, with a parameter $\\beta$. We need to perform some type of inference to find the best value of $\\beta$ to use. We will often denote the best parameter with a hat, so let's call the best value $\\hat\\beta$. There are much more sophisticated way of finding the best parameter, but for now let's find it by just taking the mean of the observed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta_hat = observed_data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the \"best\" value of beta, we can predict the times between goals of the the *next* 20 goals to happen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 23.47594048,   0.84723569,  87.54684534,   6.3286481 ,\n",
       "         0.53022768,  14.30698264,  30.37813871,   9.22017684,\n",
       "         8.34499249,  10.87598466,  10.03363718,   6.41006572,\n",
       "        24.47835214,  16.38397645,  41.86606212,   2.63869613,\n",
       "        50.93782915,  10.59829603,   0.47275462,  10.01354213])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = np.random.exponential(beta_hat, 20)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obvious question to ask it then this: how did we do. To determine that, we would need to actually observe the next 20 goals and see how their times compare to the generated values. This is a very simple, model so we wouldn't expect the goals to exactly match these predictions, but we might hope that in some aggregate sense our predictions are accurate. In future notebooks, we will go into great detail about assessing how well a model works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
